import os
import json
import asyncio
import aiohttp
from supabase import create_client
from dotenv import load_dotenv
import time
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

load_dotenv()

class ICLREmbeddingGenerator:
    def __init__(self):
        # OpenAI API ì„¤ì •
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.openai_base_url = "https://api.openai.com/v1"
        self.model_name = "text-embedding-3-small"
        
        # Supabase ì„¤ì •
        self.supabase_url = os.getenv("SUPABASE_URL")
        self.supabase_key = os.getenv("SUPABASE_KEY")
        self.supabase = create_client(self.supabase_url, self.supabase_key)
        
        # ë°°ì¹˜ ì„¤ì •
        self.batch_size = 10  # ì‘ì€ ë°°ì¹˜ í¬ê¸°ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        self.max_retries = 3
        self.retry_delay = 1
        
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        if not self.supabase_url or not self.supabase_key:
            raise ValueError("Supabase í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    async def get_embedding(self, session: aiohttp.ClientSession, text: str) -> list:
        """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        headers = {
            "Authorization": f"Bearer {self.openai_api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "input": text,
            "model": self.model_name
        }
        
        for attempt in range(self.max_retries):
            try:
                async with session.post(
                    f"{self.openai_base_url}/embeddings",
                    headers=headers,
                    json=data,
                    ssl=False  # SSL ê²€ì¦ ë¹„í™œì„±í™”
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        return result["data"][0]["embedding"]
                    else:
                        error_text = await response.text()
                        logger.error(f"OpenAI API ì˜¤ë¥˜: {response.status} - {error_text}")
                        
                        if response.status == 429:  # Rate limit
                            wait_time = (attempt + 1) * self.retry_delay * 2
                            logger.info(f"Rate limit ë„ë‹¬. {wait_time}ì´ˆ ëŒ€ê¸°...")
                            await asyncio.sleep(wait_time)
                        else:
                            raise Exception(f"API ì˜¤ë¥˜: {response.status}")
                            
            except Exception as e:
                logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {e}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay)
                else:
                    raise
        
        raise Exception("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
    
    def prepare_text_for_embedding(self, title: str, abstract: str) -> str:
        """ì œëª©ê³¼ ì´ˆë¡ì„ ê²°í•©í•˜ì—¬ ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤."""
        title = title.strip() if title else ""
        abstract = abstract.strip() if abstract else ""
        
        # ê²°í•© (ì œëª©ì„ ë” ì¤‘ìš”í•˜ê²Œ ê°€ì¤‘ì¹˜)
        combined_text = f"Title: {title}\n\nAbstract: {abstract}"
        return combined_text
    
    def get_iclr_papers_without_embeddings(self):
        """ì„ë² ë”©ì´ ì—†ëŠ” ICLR ë…¼ë¬¸ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            # ICLR ë…¼ë¬¸ ì¤‘ ì„ë² ë”©ì´ ì—†ëŠ” ê²ƒë“¤ë§Œ ì¡°íšŒ
            result = self.supabase.table("papers").select("*").eq("conference", "ICLR").is_("combined_embedding", "null").execute()
            papers = result.data
            
            logger.info(f"ì„ë² ë”©ì´ ì—†ëŠ” ICLR ë…¼ë¬¸: {len(papers)}ê°œ")
            return papers
            
        except Exception as e:
            logger.error(f"ICLR ë…¼ë¬¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def update_paper_embeddings(self, paper_id: int, title_embedding: list, 
                               abstract_embedding: list, combined_embedding: list) -> bool:
        """Supabaseì— ë…¼ë¬¸ ì„ë² ë”©ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        try:
            result = self.supabase.table("papers").update({
                'title_embedding': title_embedding,
                'abstract_embedding': abstract_embedding,
                'combined_embedding': combined_embedding
            }).eq('id', paper_id).execute()
            
            return True
            
        except Exception as e:
            logger.error(f"ë…¼ë¬¸ {paper_id} ì„ë² ë”© ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    async def process_paper(self, session: aiohttp.ClientSession, paper: dict) -> bool:
        """ë‹¨ì¼ ë…¼ë¬¸ì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        try:
            paper_id = paper['id']
            title = paper['title']
            abstract = paper['abstract']
            
            logger.info(f"ë…¼ë¬¸ ì²˜ë¦¬ ì¤‘: {title[:50]}...")
            
            # ê°œë³„ ì„ë² ë”© ìƒì„±
            title_embedding = await self.get_embedding(session, title)
            await asyncio.sleep(0.2)  # Rate limit ë°©ì§€
            
            abstract_embedding = await self.get_embedding(session, abstract)
            await asyncio.sleep(0.2)  # Rate limit ë°©ì§€
            
            # ê²°í•© ì„ë² ë”© ìƒì„±
            combined_text = self.prepare_text_for_embedding(title, abstract)
            combined_embedding = await self.get_embedding(session, combined_text)
            await asyncio.sleep(0.2)  # Rate limit ë°©ì§€
            
            # DB ì—…ë°ì´íŠ¸
            success = self.update_paper_embeddings(
                paper_id, title_embedding, abstract_embedding, combined_embedding
            )
            
            if success:
                logger.info(f"âœ… ë…¼ë¬¸ {paper_id} ì„ë² ë”© ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                return True
            else:
                logger.error(f"âŒ ë…¼ë¬¸ {paper_id} ì„ë² ë”© ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ë…¼ë¬¸ {paper.get('id', 'unknown')} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return False
    
    async def generate_iclr_embeddings(self):
        """ICLR ë…¼ë¬¸ë“¤ì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        logger.info("ICLR ë…¼ë¬¸ ì„ë² ë”© ìƒì„± ì‹œì‘")
        
        # ì„ë² ë”©ì´ ì—†ëŠ” ICLR ë…¼ë¬¸ë“¤ ê°€ì ¸ì˜¤ê¸°
        papers = self.get_iclr_papers_without_embeddings()
        
        if not papers:
            logger.info("ëª¨ë“  ICLR ë…¼ë¬¸ì— ì„ë² ë”©ì´ ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return {"total_processed": 0, "successful_updates": 0}
        
        logger.info(f"ì²˜ë¦¬í•  ICLR ë…¼ë¬¸: {len(papers)}ê°œ")
        
        successful_updates = 0
        total_processed = 0
        
        # HTTP ì„¸ì…˜ ìƒì„± (SSL ê²€ì¦ ë¹„í™œì„±í™”)
        connector = aiohttp.TCPConnector(ssl=False)
        async with aiohttp.ClientSession(connector=connector) as session:
            # ë°°ì¹˜ ì²˜ë¦¬
            for i in range(0, len(papers), self.batch_size):
                batch = papers[i:i+self.batch_size]
                batch_num = i // self.batch_size + 1
                total_batches = (len(papers) + self.batch_size - 1) // self.batch_size
                
                logger.info(f"ğŸ“¤ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ)")
                
                batch_success = 0
                for paper in batch:
                    success = await self.process_paper(session, paper)
                    if success:
                        batch_success += 1
                        successful_updates += 1
                    total_processed += 1
                
                logger.info(f"âœ… ë°°ì¹˜ {batch_num} ì™„ë£Œ: {len(batch)}ê°œ ì¤‘ {batch_success}ê°œ ì„±ê³µ")
                
                # ì§„í–‰ë¥  í‘œì‹œ
                progress = (batch_num / total_batches) * 100
                logger.info(f"ğŸ“ˆ ì§„í–‰ë¥ : {progress:.1f}% ({successful_updates}/{len(papers)})")
                
                # Rate limit ë°©ì§€
                if batch_num < total_batches:
                    await asyncio.sleep(1)
        
        # ê²°ê³¼ ë°˜í™˜
        stats = {
            "total_processed": total_processed,
            "successful_updates": successful_updates,
            "success_rate": (successful_updates / total_processed * 100) if total_processed > 0 else 0
        }
        
        logger.info(f"ICLR ì„ë² ë”© ìƒì„± ì™„ë£Œ: {stats}")
        return stats
    
    def get_iclr_embedding_stats(self):
        """ICLR ë…¼ë¬¸ì˜ ì„ë² ë”© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            # ì „ì²´ ICLR ë…¼ë¬¸ ìˆ˜
            total_result = self.supabase.table("papers").select("id", count="exact").eq("conference", "ICLR").execute()
            total_iclr = total_result.count
            
            # ì„ë² ë”©ì´ ìˆëŠ” ICLR ë…¼ë¬¸ ìˆ˜
            with_embeddings_result = self.supabase.table("papers").select("id", count="exact").eq("conference", "ICLR").not_.is_("combined_embedding", "null").execute()
            iclr_with_embeddings = with_embeddings_result.count
            
            # ì»¤ë²„ë¦¬ì§€ ê³„ì‚°
            coverage = (iclr_with_embeddings / total_iclr * 100) if total_iclr > 0 else 0
            
            return {
                "total_iclr_papers": total_iclr,
                "iclr_with_embeddings": iclr_with_embeddings,
                "iclr_without_embeddings": total_iclr - iclr_with_embeddings,
                "embedding_coverage_percent": round(coverage, 1)
            }
            
        except Exception as e:
            logger.error(f"ICLR í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ“š ICLR ë…¼ë¬¸ ì„ë² ë”© ìƒì„±ê¸°")
    print("=" * 60)
    
    try:
        # ì„ë² ë”© ìƒì„±ê¸° ì´ˆê¸°í™”
        generator = ICLREmbeddingGenerator()
        
        # í˜„ì¬ ICLR ì„ë² ë”© í†µê³„ í™•ì¸
        print("ğŸ“Š í˜„ì¬ ICLR ì„ë² ë”© í†µê³„:")
        stats = generator.get_iclr_embedding_stats()
        for key, value in stats.items():
            print(f"  - {key}: {value}")
        print()
        
        if stats.get('iclr_without_embeddings', 0) == 0:
            print("âœ… ëª¨ë“  ICLR ë…¼ë¬¸ì— ì„ë² ë”©ì´ ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return
        
        # ì‚¬ìš©ì í™•ì¸
        response = input(f"ğŸš€ {stats.get('iclr_without_embeddings', 0)}ê°œì˜ ICLR ë…¼ë¬¸ì— ì„ë² ë”©ì„ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if response.lower() != 'y':
            print("ì„ë² ë”© ìƒì„±ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
        
        # ì„ë² ë”© ìƒì„± ì‹¤í–‰
        start_time = time.time()
        results = await generator.generate_iclr_embeddings()
        end_time = time.time()
        
        print(f"\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“Š ê²°ê³¼:")
        print(f"  - ì´ ì²˜ë¦¬ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
        print(f"  - ì²˜ë¦¬ëœ ë…¼ë¬¸: {results['total_processed']}ê°œ")
        print(f"  - ì„±ê³µí•œ ì—…ë°ì´íŠ¸: {results['successful_updates']}ê°œ")
        print(f"  - ì„±ê³µë¥ : {results['success_rate']:.1f}%")
        
        # ìµœì¢… ICLR í†µê³„ í™•ì¸
        print(f"\nğŸ“ˆ ìµœì¢… ICLR ì„ë² ë”© í†µê³„:")
        final_stats = generator.get_iclr_embedding_stats()
        for key, value in final_stats.items():
            print(f"  - {key}: {value}")
        
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main()) 